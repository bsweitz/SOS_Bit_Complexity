\section{Examples with Rich Solution Spaces}
\label{sec:nicespaces}
In this section we present examples of polynomial systems that admit rich solution spaces. First, we consider the case $S \subseteq \{0,1\}^n$. In this case, the spectral richness is a consequence of the following easy observation.
\begin{lemma} \label{lem:integer}
	Let $M \in \R^{N \times N}$ be an integer matrix with $|M_{ij}| \leq B$ for all $i,j \in [N]$.  The smallest non-zero eigenvalue of $M$ is at least 
	$(BN)^{-N}$.
\end{lemma}
\begin{proof}
Let $A$ be a full-rank principal minor of $M$ and w.l.o.g. let it be at the upper-left block of $M$. We claim the least eigenvalue of $A$ lower bounds the least nonzero eigenvalue of $M$.
%
Since $M$ is symmetric, there must be a $C$ such that
\[M = \left[\begin{tabular}{c} $I$ \\ $C$\end{tabular}\right]A\left[\begin{tabular}{cc} $I$ & $C^T$\end{tabular}\right].\]
Let $P = [I, C^T]$, $\rho$ be the least eigenvalue of $A$, and $x$ be a vector perpendicular to the zero eigenspace of $A$. Then we have $x^TMx \geq \rho x^TP^TPx$,
but $x$ is also perpendicular to the zero eigenspace of $P^TP$. Now $P^TP$ has the same nonzero eigenvalues as $PP^T = I + C^TC \succeq I$, and thus $x^TP^TPx \geq 1$, and so every nonzero eigenvalue of $A$ is at least $\rho$. Now $A$ is a full-rank bounded integer matrix with dimension at most $N$. The magnitude of its determinant is at least $1$ and all eigenvalues are at most $N \cdot B$.  Therefore, its least eigenvalue must be at least $(BN)^{-N}$ in magnitude. 
\end{proof}


\begin{lemma}\label{lem:integer-rich}
Let $\cP$ and $\cQ$ be such that $S \subseteq \{0,1\}^n$. Then $S$ is $\delta$-spectrally rich with $\frac{1}{\delta} = 2^{\poly(n^d)}$.
\end{lemma}
\begin{proof}
	Recall $M = E_{\alpha \in S}[{\bf v}(\alpha){\bf v}(\alpha)^T]$, and note that $|S| \cdot M$ is an integer matrix with entries at most $2^n$.  The proof follows by applying \prettyref{lem:integer}. 
\end{proof}

To prove completeness, we typically want to show two things. First, that every degree $d$ polynomial in $\langle \cP\rangle$ has a degree at most $k$ derivation. Second, that there are no polynomials outside $\langle \cP\rangle$ that are zero on $S$. This second condition can be thought of as saying that the set of equations $\cP$ is somehow maximal, i.e., if there are extra polynomial equalities implied by $\cQ$, they should be included in $\cP$.  Here we consider a few examples. 



\paragraph*{\textsc{Max-CSP}: $\cP = \{x_i^2 - x_i | i \in [n]\}$}
	Here $S = \{0,1\}^n$.  Any polynomial $p$ of degree $d$ can be multilinearized one monomial at a time.  Specifically, we can find degree $d$ multilinear $p^*$ such that $p - p^* = 0$ has a degree $d$ derivation from $\cP$.  Furthermore, the multilinear polynomial $p^*$ is zero over $S$ if and only if all its coefficients are zero.  Thus $\cP$ is $d$-complete up to degree $d$ for all $d \in \N$.  

\paragraph*{\textsc{Max-Clique}: $\cP = \{x_i^2 - x_i | i \in [n]\} \cup \{x_ix_j | (i,j) \notin E\}$}
Here $S$ is the set of all cliques in the graph.  Suppose $p$ is a polynomial that is identically zero over $S$.  Without loss of generality, we may assume $p$ is multilinear, if otherwise we can multilinearize it using $\{ x_i^2 - x_i | i \in [n]\}$.  For a multilinear polynomial $p(x) = \sum_{\alpha \subset [n]} \hat{p}_\alpha x_{\alpha}$, we claim that if $p(x) = 0 \forall x \in S$ then for all cliques $\alpha \subset [n]$, the corresponding coefficient $\hat{p}_\alpha = 0$, i.e., all non-zero coefficients of $p$ are non-cliques.
%
Suppose not, then let $\alpha$ be the smallest clique with $\hat{p}_\alpha \neq 0$.  Then, we will have $p( \Ind_{\alpha}) = \hat{p}_\alpha \neq 0$, a contradiction.
% 
Since all coefficients of $p$ are non-cliques, each monomial in $p$ can be eliminated using an appropriate polynomial from $\{ x_i x_j | (i,j) \notin E\}$.

\begin{remark}
	More generally, the above two cases are special cases of the following general setup: $\cQ$ is empty, and $\cP$ is a Gr\"obner basis. A Gr\"obner basis for an ideal is a generating set of polynomials that allow a well-defined multivariate polynomial division (see \cite{Grobner} for more information). Computing the Gr\"obner basis is often the first step in practical polynomial equation solvers, and we note the following easy lemma:
\begin{lemma}\label{lem:grobner}
If $\cQ = \emptyset$ and $\cP$ is a Gr\"obner basis for $\langle \cP\rangle$, then $S$ is $d$-complete up to degree $d$. 
\end{lemma}
\begin{proof}
If $\cP$ is a Gr\"obner basis, then every degree $d$ polynomial in $\langle \cP\rangle$ has a degree $d$ derivation via multivariate division. Because $\cQ = \emptyset$, the polynomials that are zero on $S$ are exactly the polynomials in $\langle \cP\rangle$. 
\end{proof}

\end{remark}

%Two polynomial optimization problems captured by \prettyref{lem:grobner} are the \textsc{Max-CSP} problem, and the \textsc{Max-Clique} problem. While this fact was already known for \text{Max-CSP}, our technique is the first one to give results for systems with more than just Boolean constraints.
%Gr\"obner bases are useful, but often extremely expensive to compute, and having access to one is a luxury in many optimization problems. 
%
%Because of this, one might worry that Gr\"obner bases are the \emph{only} settings with rich solutions, and that \prettyref{thm:main} will not be very broadly applicable. 
%
%We dispel this notion in \prettyref{sec:balance} by showing the natural description of the \textsc{Max-Bisection} ideal is $d$-complete, even though its Gr\"obner basis has exponential size. Likewise, in \cite{Braun:2016:MPN:2884435.2884510}, it was proven that the \textsc{Matching} constraints are $2d$-complete, which is another set of constraints that is not a Gr\"obner basis. 


\paragraph*{\textsc{Balanced Separator}: $\cP = \{x_i^2 - x_i | i \in [n]\}$, $\cQ = \{2n/3 - \sum_i x_i, \sum_i x_i - n/3\}$}
%Furthermore, if $\cQ$ is pretty simple, it is not too difficult to prove that it does not introduce any additional low degree polynomial equalities. 
%
%Here the system is given by
%\[\cP = \{x_i^2-x_i | i \in [n]\} \text{ and } \cQ = \{\sum_i x_i - n/3, 2n/3 - \sum_i x_i\}\]
The solution space $S$ here is all bit strings with hamming weight between $n/3$ and $2n/3$. 
%
Suppose $r$ is a polynomial that is zero on $S$.  
%
Without loss of generality, we may assume that $r$ is multilinear by using the constraints $\{x_i^2 - x_i | i \in [n]\}$.
%
Suppose $r$ is a non-zero multilinear polynomial which is zero on $S$, then its symmetrized version $r^* = \frac{1}{n!}\sum_{\sigma \in \cS_n} \sigma r$ must also be zero on $S$, where $\sigma$ acts by permuting the variable names. However, $r^*$ is a univariate polynomial in $\sum_i x_i$ (modulo the Boolean constraints). 
%
This univariate polynomial has $n/3$ zeros, and thus must have degree at least $n/3$. Since symmetrizing doesn't change degree, we conclude that $r$ also has degree at least $n/3$. Thus every non-zero multilinear polynomial that is zero on $S$ but not in $\langle \cP\rangle$, has degree at least $n/3$. 
%
Therefore the system is $d$-complete up to degree $d$ for $d \leq \frac{n}{3}$.
%Moreover, eve 
%Further, $\cP$ is a Gr\"obner basis, so $(\cP, \cQ, S)$ is $d$-complete as long as $d < n/3$. 
%
The polynomials in $\cQ$ can be perturbed by $1/2$ to make them $1/2$-robust, and thus $S$ is rich for $(\cP, \cQ)$. 

\paragraph*{\textsc{Matching}: $\cP = \{x_{ij}^2 - x_{ij} | i,j \in [n]\} \cup \{\sum_i x_{ij} - 1 | i \in [n]\} \cup \{x_{ij}x_{ik} | i,j,k \in [n]\}$} These constraints are $2d$-complete as proven in \cite{Braun:2016:MPN:2884435.2884510}.

\paragraph*{\textsc{Max-Bisection}: $\cP = \{x_i^2 - x_i | i \in [n]\} \cup \{\sum_i x_i - n/2\}$} We will prove in \prettyref{sec:balance} that these constraints are $d$-complete. The proof will be very similar to the one for \textsc{Matching}, due to the similar symmetry of the constraints.

\paragraph*{\textsc{Unit-Vector}: $\cP = \{\sum_i x_i^2 - 1\}$} Here $S = \{x: \|x\| = 1\}$. This constraint appears frequently in tensor norm problems as a way to enforce scaling. Since $\cQ = \emptyset$, it is clearly robust. It may be well-known that $\cP$ is $d$-complete, but we could not find a reference so we record it here for completeness. Let $p(x)$ be any degree $d$ polynomial which is zero on the unit sphere, and define $p_0(x) = p(x) + p(-x)$. Clearly $p_0$ is also zero on the unit sphere, with degree $k = 2\lfloor (d+1)/2 \rfloor$. Note that $p_0$ has only terms of even degree. 
%
Define a sequence of polynomials $\{p_i\}_{i \in \{0,\ldots, k\}}$ as follows.
Define $q_i$ to be the part of $p_i$ which has degree strictly less than $k$, and let $p_{i+1} = p_i + q_i\cdot(\sum_i x_i^2 - 1)$. Then each $p_i$ is zero on the unit sphere and has no monomials of degree strictly less than $2i$. Thus $p_{k/2}$ is homogeneous of degree $k$. But then $p(tx) = t^kp_k(x) = 0$ for any unit vector $x$ and $t > 0$, and thus $p_k(x)$ must be the zero polynomial. This implies that $p_0$ is a multiple of $\sum_i x_i^2 - 1$. The same logic shows that $p(x) - p(-x)$ is also a multiple of $\sum_i x_i^2 - 1$, and thus so is $p(x)$. Now $\langle \cP\rangle$ is principal, so every degree $d$ polynomial in it has a degree $d$ derivation, so $(\cP, \cQ, S)$ is $d$-complete.

To prove spectral-richness, we note that in \cite{10.2307/2695802} the author gives an exact formula for each entry of the matrix $M = \int_{S} p(x)$ for any polynomial $p$. The formulas imply that $(n+d)!\pi^{-n/2} M$ is an integer matrix with entries (very loosely) bounded by $(n+d)!d!2^n$. By \prettyref{lem:integer}, we conclude that $S$ is $\delta$-spectrally rich with $1/\delta = 2^{\poly(n^d)}$.


We collect the examples discussed in this section here:
\begin{corollary}\label{cor:examples}
The following constraints admit rich solutions:
\begin{itemize}
\item \textsc{Max-CSP}: $\cP = \{x_i^2 - x_i | i \in [n]\}$. 
\item \textsc{Max-Clique}: $\cP = \{x_i^2 - x_i | i \in [n]\} \cup \{x_ix_j | (i,j) \notin E\}$.
\item \textsc{Balanced Separator}: $\cP = \{x_i^2 - x_i | i \in [n]\}$, $\cQ = \{2n/3 - \sum_i x_i, \sum_i x_i - n/3\}$.
\item \textsc{Matching}: $\cP = \{x_{ij}^2 - x_{ij} | i,j \in [n]\} \cup \{\sum_i x_{ij} - 1 | i \in [n]\} \cup \{x_{ij}x_{ik} | i,j,k \in [n]\}$.
\item \textsc{Max-Bisection}: $\cP = \{x_i^2 - x_i | i \in [n]\} \cup \{\sum_i x_i - n/2\}$.
\item \textsc{Unit-Vector}: $\cP = \{\sum_i x_i^2 - 1\}$.
\end{itemize}
\end{corollary}

\subsection{Limitations}
While \prettyref{thm:main} allows us to prove that many different systems of polynomial constraints have well-behaved SoS proofs, there are a few areas where it comes up short. Most noticeably, to contain a rich set of solutions the solution space has to be nonempty. This can be a problem when trying to find SoS proofs of infeasibility. For example, one common technique is to introduce lower bounds on an objective function $f(x)$ of a maximization problem as constraints and attempt to use SoS to find a refutation, i.e. a proof of non-negativity for the constant polynomial $-1$. We are unable to show that these proofs can be taken to have polynomial bit complexity since they have empty solution spaces. As another example, we are unable to use our framework to show that refutations of the knapsack constraints use only polynomially many bits, even though it is clear by simply examining these known refutations that they only involve small coefficients. 