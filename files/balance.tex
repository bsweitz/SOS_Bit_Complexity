\section{\textsc{Max-Bisection} Constraints}\label{sec:balance}
In this section, we prove our earlier claim that the \textsc{Max-Bisection} constraints admit rich solutions. Recall the constraints:
\[\cP(n) = \left\{x_i^2 - x_i | i \in [2n]\right\} \cup \left\{\sum_i x_i - n\right\}.\]
%
Recall that to prove $S$ is rich, we have to prove that it is spectrally rich, robust, and complete. Since the solution space lies in the hypercube, it is spectrally rich by \prettyref{lem:integer-rich}, and it is clearly robust since $\cQ$ is empty. It remains to prove that it is complete for some $k$. This proof follows a very similar path to \cite{Braun:2016:MPN:2884435.2884510}, due to the similar symmetry of the constraints. 
\begin{lemma}
$\cP(n)$ is $d$-complete for any $d \leq n$.
\end{lemma}
\begin{remark}
REVIEWER TODO
\end{remark}
\begin{proof}
Let $S(n)$ denote the solution space of $\cP(n)$, and let $M = \E_{\alpha \in S}[{\bf v}(\alpha){\bf v}(\alpha)^T]$. Any zero eigenvector $c$ of $M$ can be associated with a polynomial $c^T{\bf v}$. Since 
\[c^TMc = \sum_\alpha (c^T{\bf v}(\alpha))^2 = 0,\]
we must have $c^Tv(\alpha) = 0$ for each $\alpha \in S$. We argue that any degree $d$ polynomial which is identically zero on $S(n)$ must have a degree $d$ derivation from $\cP(n)$. 

We proceed by induction on $d$. If $d = 0$, the only constant polynomial zero on $S(n)$ is the zero polynomial, which has the trivial derivation. Now consider the case of $d = c+1$. We proceed in two parts. First, if $r$ is fully symmetric, we show that it has a degree $d$ derivation. Secondly, for any polynomial $p$ which is zero on $S(n)$, we prove that $p - \frac{1}{(2n)!}\sum_{\sigma \in \cS_n} \sigma p$ has a degree $d$ derivation from $\cP$, where $\sigma$ acts on $p$ by permuting the labels of the variables. Taken together, these two facts imply that $r$ has a degree $d$ derivation from $\cP(n)$.

To prove the first part, note that a symmetric polynomial $r$ is a linear combination of the elementary symmetric polynomials $e_1,\dots,e_c$, and it is clear that $e_k(x)$ can be derived by taking the polynomial $(\sum_i x_i - n)^k$, reducing it to multilinear using the boolean constraints, and then reducing by $e_l(x)$ for each $l < k$. This will result in a constant polynomial, which must be the zero polynomial since we are only adding polynomials which are zero on $S(n)$, so the resulting polynomial must be zero on $S(n)$. 

To prove the second part, let $\sigma_{ij}$ be the transposition of labels $i$ and $j$, and consider the polynomial $r - \sigma_{ij}r$. Writing $r = r_ix_i + r_jx_j + r_{ij}x_ix_j + q_{ij}$, where none of $r_i$,$r_j$,$r_{ij}$, nor $q_{ij}$ depend on $x_i$ or $x_j$, we can rewrite
\[r - \sigma_{ij}r = (r_i - r_j)(x_i - x_j).\]
Now because $r - \sigma_{ij}r$ evalutes to zero on any boolean string with exactly $n$ ones, if we set $x_i = 1$ and $x_j = 0$, we know that $r_i - r_j$ is a polynomial that must evaluate to zero on any boolean string with exactly $n-1$ ones. Because $\deg (r_i - r_j) = d-1$, by the inductive hypothesis, $r_i - r_j$ has a degree $d-1$ proof from $\cP(n-1)$ (since $d \leq n$, clearly $d-1 \leq n-1$). This implies that $(r_i - r_j)(x_i - x_j)$ has a degree $d-1$ proof from $\cP(n)$:
\begin{align*}
(r_i - r_j)(x_i - x_j) &= \left[\sum_{t \neq i,j} \lambda_t\cdot (x_t^2 - x_t) + \lambda \cdot \left(\sum_{t \neq i,j} x_t - (n-1)\right)\right](x_i - x_j) \\
&= \sum_{t} \lambda'_t \cdot (x_t^2 - x_t) + \lambda \cdot \left(\sum_{t \neq i,j} x_t - (n-1) + (x_i + x_j - 1)\right)(x_i - x_j)\\
&= \sum_t \lambda'_t \cdot (x_t^2 - x_t) +\lambda' \cdot \left(\sum_t x_t - n\right)
\end{align*}
where we used the fact that $(x_i + x_j - 1)(x_i - x_j) - (x_i^2 - x_i) + (x_j^2 - x_j) = 0$. The degree of this derivation is at most $d$ because each $\lambda_t$ has degree at most $d-3$, and $\lambda'_t = \lambda_t(x_i - x_j)$, and similarly for $\lambda$. Thus the inductive hypothesis implies that $r - \sigma_{ij}r$ has a degree $d$ derivation, and since transpositions generate the symmetric group, this implies that $r - \frac{1}{(2n)!}\sum_{\sigma \in \cS_n} \sigma r$ has a degree $d$ proof from $\cP(n)$.
\end{proof}

\begin{remark}
In this example, $\cP$ is not a Gr\"obner basis for its ideal $\langle \cP \rangle$. 
%
Indeed, the Gr\"obner basis for this ideal has exponential size. This is an example where our framework is applicable, even though Gr\"obner bases are intractable to compute. 
\end{remark}
